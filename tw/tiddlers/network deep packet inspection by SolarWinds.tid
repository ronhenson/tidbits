created: 20150406152000000
creator: ronh
modified: 20200716152909159
modifier: ronh
revision: 0
tags: #Diagnosis #Training #Tidbit #Tech #Network
title: network deep packet inspection by SolarWinds
type: text/vnd.tiddlywiki

{{||journalHeaderTemplate}}

<html>
<head>
<META charset="utf-8">
<title id="infoObjectTitle"> tb:Network Deep Packet Inspection by SolarWinds </title>
<link href="css/tb.css", rel="stylesheet" type="text/css">

<script language='JavaScript' type='text/JavaScript'>
// Define Title, Description, Creation Date and tags
var infoObjectRH = {
	"info" : {
		"title" : "Network Deep Packet Inspection by SolarWinds",
		"description" : "Network sniffing and diagnosing",
		"cdate" : "2015-04-06T15:20:31+00:00",
		"tags" : [ { "tag" : "tidbits" },
			{ "tag" : "network" },
			{ "tag" : "training" },
			{ "tag" : "diagnosis" },
			{ "tag" : "sniffing" } 
		] 
	} 
};

</script>

</head>
<body>
<script src="tidbit.js"></script>

 <HR class="h1">
</div>
<!-- ALTERING THE NET LINE <DIV..  WILL REQUIRE A CODE CHANGE IN tdbi_new SCRIPT -->
<div id="tidbitbody">

! Network sniffing and diagnosing

<h1> Lesson 1: Packet Analysis: What is it? And what can it provide? </h1>
<pre> <code>
From: SolarWinds <SolarWindsCommunityTeam@solarwinds.com>
To: ron.henson@gmail.com
Subject: [SWI] Lesson 1/8: Meet your instructor for deep packet inspection email course
Date: Tue, 31 Mar 2015 16:34:34 -0500 (CDT)
Reply-To: SolarWindsCommunityTeam@solarwinds.com


Hi there,

And welcome to Lesson 1 of the Deep Packet Inspection (DPI) for Quality of Experience (QoE) Monitoring Email Course. I’m Leon Adato, Head Geek for network monitoring at SolarWinds®, and your facilitator for this course. Over the next 8 days, you'll receive 1 email per day containing each lesson of your class curriculum. Each will have [SWI] in the subject line, so you can set up a filter if you'd like. 

>> https://thwack.solarwinds.com/people/adatole?CMP=EMC-MKT-SWI-DPI_Course_Lesson_1-X-TH_LeonAdato-TXT

During this course, anytime you have a question feel free to head to the DPI study group I’ve set up on our customer community, thwack®. There, you will find a list of additional helpful resources on deep packet inspection, along with the ability to post discussions and ask questions. Note that you’ll have to create a thwack community profile to post.

 >> https://thwack.solarwinds.com/groups/dpi-online-course-study-group?CMP=EMC-MKT-SWI-DPI_Course_Lesson_1-X-TH_DPI_Login-TXT  

Lesson 1: Packet Analysis: What is it? And what can it provide?

Packet Analysis

The IT industry is increasingly recognizing and leveraging the value and utility of packet-level analysis—also called Deep Packet Inspection or just Packet Analysis—for quickly and accurately identifying the true source and nature of network and application reliability and performance problems.

Packet analysis involves ‘capturing’ (making a copy of) and inspecting network packets that flow between client and server devices. Typically, this is accomplished with a tool commonly referred to as a ‘Sniffer,’ which is the name of one of the first industry standard tools designed for packet analysis.

More recently, an open-source software application called ‘Wireshark®’ has become the leading tool for manual packet analysis. Wireshark can be installed on a workstation or laptop. It utilizes a promiscuous (capture everything) mode driver with a built-in network interface card, making this a very capable tool. However, this solution is typically moved around and used on an as-needed basis. There’s also a lot of skill required to properly configure the software, perform captures, and analyze/interpret packet flows.

 >> https://www.wireshark.org/?CMP=EMC-MKT-SWI-DPI_Course_Lesson_1-X-WSHP-TXT  

A number of vendors offer specialized appliances to perform high-throughput and/or deep packet inspection at the enterprise level, but these tools can be very expensive to deploy, especially when deploying them to a number of locations with the expectation of providing optimal coverage.

What Packet Analysis Can Provide

In addition to transporting data between clients and servers, modern networking protocols such as TCP/IP are tasked with ensuring the reliable delivery of packets, minimizing packet loss, and maintaining data flow controls in order to optimize network throughput—most importantly when dealing with congested networks. By inspecting packet flows and protocol parameters, useful information about network performance can be extracted. 

Packet analysis can also identify all types and relative volumes of application traffic flowing over a network based on the host IP addresses, ports, and protocols in use.

By inspecting and interpreting network data flows at the packet level, a wealth of performance related information can be gleaned. The following lessons discuss and illustrate some of the most useful of the possibilities, starting with lesson 2 next week – Network Response Time. 

If you’re enjoying this course or have questions, please share your feedback with the community here:

 >> https://thwack.solarwinds.com/groups/dpi-online-course-study-group?CMP=EMC-MKT-SWI-DPI_Course_Lesson_1-X-TH_DPI_Login-TXT  

See you tomorrow!

Leon Adato,
Head Geek at SolarWinds
SolarWinds - The Power to Manage IT

Click here to join thwack, the SolarWinds community of over 125,000 IT Pros contributing to answer your questions. Gain direct access to product managers, download custom templates and reports, and much more!
 >> http://thwack.solarwinds.com/community/solarwinds-community/announcements/blog/2013/11/04/you-dont-know-thwack--the-onboarding-mission  

Already a user? Click here to visit the SolarWinds Customer Portal for up to the minute information about your products and other special offers.
 >> https://customerportal.solarwinds.com/  

This email was sent to: ron.henson@gmail.com

7171 Southwest Parkway, Building 400, Austin, TX 78735
P: 866.530.8100 | F: 512.682.9301
www.solarwinds.com
 
Email Preferences >> http://solarwinds.mkt5016.com/Preference_Center/
Unsubscribe >> http://solarwinds.mkt5016.com/unsubscribe/
</code> </pre>

<h1> Lesson 2: Network Response Time </h1>
<pre> <code>
From: SolarWinds <SolarWindsCommunityTeam@solarwinds.com>
To: ron.henson@gmail.com
Subject: [SWI] Lesson 2/8: Network Response Time
Date: Thu, 2 Apr 2015 10:14:37 -0500 (CDT)
Reply-To: SolarWindsCommunityTeam@solarwinds.com


Welcome to lesson 2 of your DPI for QoE Monitoring Email Course. Today we’ll cover network response time: what it is, why it’s important, and what causes it to increase.

Network Response Time
Network response time—or network path latency, as it’s also known—is a measure of the amount of time required for a packet to travel across a network path from sender to receiver. When network path latencies occur, application performance is often adversely affected.

Causes of High Network Response Times
Four major factors affect network path latency:

• Speed-of-Light Propagation Delay
• Network Routing/Geographical Distance
• Serialization Delay across Wide Area Network (WAN) Links
• Queuing Delays in Network Devices

Speed-of-Light Propagation Delay
Electrical signals travel through the vacuum of space at the speed of light—about 186,000 miles per second or 671 million miles per hour, depending on your preference. Despite this almost unimaginable speed, it still takes a finite amount of time for an electrical signal to travel across distances. For example, the straight-line distance between New York to Chicago is about 713 miles—it takes light about 3.8 milliseconds (ms) to travel that far.

However, it takes longer for an electrical signal to propagate through physical media, such as the copper and fiber optic cables commonly used in telecommunications. Electrical signals travel through copper and fiber at only ~66% of light speed—so it would take about 5.8 ms for a signal to get from New York to Chicago in this scenario. And, of course, the longer the distance between sender and receiver, the longer it takes for the signals to arrive.

Network Routing/Geographical Distance
The propagation delay example above represented an ideal, straight-line distance. In the real world, signals routed between New York and Chicago would most likely go through several major switching centers in locations not directly between the two end-points. Also, the cabling between these switching centers would by necessity be laid along opportunistic paths beside railroads and major highways and other right-of-way corridors. The end result being a dogleg physical route that can end up being much longer than the ideal straight-line path.

This additional distance can add a considerable amount of network path delay. It’s not unusual to see Round Trip Time (RTT) (Client to Server and Return) network latencies around 50-100 ms or more over typical US or Europe/UK network paths, and much higher than that over trans-global distances or satellite hops.

Serialization Delay across Wide Area Network (WAN) Links
Although network access and Internet links out of and between a company’s major data centers, they’re usually designed for high bandwidths (600+ Mbps) to accommodate traffic demand, WAN links to distribution centers and especially branch offices that can be much smaller—ranging from 512 Kbps to 45 or 100 Mbps.

At lower link speeds, a significant amount of time can be consumed from ‘clocking’ the number of data bits contained in a typical network packet onto these lower bandwidth portions of a network path. Consider the following example:

A typical large network packet can be 1476 bytes long 1476 x 8 bits/byte = 11,808 bits

For a branch office serviced by a T-1 (1,536 Kbps available bandwidth for data), it takes 11,808 bits/1,536,000 bits/sec = .00768 or 7.68 ms

That is the time taken just to ‘clock’ or ‘serialize’ the packet data through the WAN interface and onto the link (one bit at a time, at the link speed rate) so that the data can be transmitted to the other end. The same packet would take 23 ms to serialize onto a 512 Kbps link, but only 1.2 ms to serialize onto a 10 Mbps link. There are increasingly lesser amounts of time required for higher speed links—so these delays become relatively insignificant for high-speed links.

Serialization delays obviously contribute to overall network delay. Aside from using higher speed links (which becomes increasingly expensive), there is little that can be done to reduce the effects of this type of delay, aside from using packet data compression, caching, and other techniques (which are used in WAN optimization appliances) to reduce the overall number of packets needed to service requests and/or deliver data.

Queuing Delays in Network Devices
Small-node processing and switching delays occur as packets traverse various switches and routers along a network path. However, delay time is relatively insignificant compared to the time spent when packets are held up in router buffers awaiting their turn to be transmitted across network links—especially slower WAN links.

This type of delay is closely related to the serialization delay described above. Packets stack up and wait in transmit buffer queues while packets ahead of them are serialized onto slower WAN links (which can increase when links get busy). In addition, a packet’s time in the queue can also be affected by Quality of Service (QoS) policies that may be in place to help ensure network performance is optimized for critical applications.

A short detour to discuss time-sensitive applications, QoS, and the reasons for its use is probably in order.

Tomorrow we’re onto Network Effects and Quality of Service Policies.

If you’re enjoying this course or have questions, please share your feedback with the community here:

 >>  https://thwack.solarwinds.com/groups/dpi-online-course-study-group?CMP=EMC-MKT-SWI-DPI_Course_Lesson_2-X-TH_DPI_Login-TXT  

See you tomorrow!

Leon Adato,
Head Geek at SolarWinds



SolarWinds - The Power to Manage IT

Click here to join thwack, the SolarWinds community of over 125,000 IT Pros contributing to answer your questions. Gain direct access to product managers, download custom templates and reports, and much more!
 >> http://thwack.solarwinds.com/community/solarwinds-community/announcements/blog/2013/11/04/you-dont-know-thwack--the-onboarding-mission  

Already a user? Click here to visit the SolarWinds Customer Portal for up to the minute information about your products and other special offers.
 >> https://customerportal.solarwinds.com/
</code> </pre>

<h1> Lesson 3: Network Effects on Sensitive Applications </h1>
<pre> <code>
Welcome to lesson 3 of your DPI for QoE Monitoring Email Course. Today you’ll learn how your network can affect the performance of applications and how you can ensure regular, optimal performance of critical applications through QoS policies.

Network Effects on Sensitive Applications
Some applications such as voice and video-conferencing are sensitive to packet loss, delay, and ‘jitter’ (variances in the delivery time between sequential packets).

Packet loss and jitter can affect the overall quality of a voice call (causing ‘stuttering’ and strange tonal effects), while high overall path delays can increase the noticeable effects of echo and hinder speaker interactions due to ‘talk-over’.

Packet loss and high path delays can have even more profound effects on video conferencing (aka ‘telepresence’) systems. Packet loss can cause "blockiness" and/or jerkiness of the video, as well as audio drop-outs. High network latency can cause loss of lip-synchronization because the relatively small voice packets may be delivered in a different timeframe than the larger voice content packets. Therefore, it’s important that voice and video packets flow across the network on a consistent, reliable basis.

When network congestion from short-term peaks in traffic volume occur, QoS policies can help make sure time and delay sensitive applications continue to perform as expected.

SolarWinds® VNQM for jitter and packet loss 

 >> http://www.solarwinds.com/voip-network-quality-manager.aspx?CMP=EMC-MKT-SWI-DPI_Course_Lesson_3-X-VNQM-PP-TXT  

Quality of Service Policies
Network administrators can configure QoS policies in switches and routers to mark packets from different types of applications with a ‘Differentiated Services Code Point’ (DSCP) value that identifies their relative priority. As each packet traverses the network devices along a path they may be handled differently based on their DSCP codes—this is called Per-Hop Behavior (PHB).

When a network link becomes congested, packets will receive priority based on the class of DSCP codes they've been assigned. High priority classes of DSCP codes include the Expedited Forwarding (EF) or Assured Forwarding (AF) codes that may be applied to voice and multimedia traffic. Other, less time-sensitive packets (such as email traffic) are marked as a lower priority and may sit in different router transmit queues, for longer periods of time, awaiting their turn to be sent. In cases of extreme congestion, some packets may be dropped altogether, resulting in packet loss.

When network congestion occurs, QoS policies help ensure time-and delay-sensitive applications perform as expected and that the most value is extracted from expensive network links. At the same time, these policies can also negatively affect the performance for lesser priority applications—including user-interactive/transactional applications.

Effects of Network Delay
The accumulative effects of propagation, routing, serialization, and queuing delays can result in relatively sizable total network delays between a Client and Server over typical distances.

TCP/IP protocols work to overcome these delays for bulk data transfers with techniques such as ‘sliding windows’ wherein multiple packets can be sent before they must be ‘acknowledged’, resulting in a more efficient data transfer.

Direct user interactions with a server, however, are adversely affected by higher network delays, making some applications become ‘chatty.’ This occurs when they utilize a fairly high number of request/response cycles to accomplish a task (called ‘Application Turns’ or just ‘App Turns’). Each of these request/response cycles incur the round-trip network delay time—the total time for high App Turn applications over a high latency path. It's important to note that this time can add up very quickly.

For example, loading a moderately complex Web page that contains a high number of graphic images and multiple CSS & JavaScript files can result in a LOT of requests—one for each file. If there are 35 files required to load one page over a 72 millisecond RTT path, the total time incurred from App Turns alone is: 35 x .075 = 2.625 seconds

This is just for App Turns delay—waiting for requests and responses to traverse the minimum network routing/propagation delay. This delay is in addition to any client and server processing time & other network transport delays (serialization and queuing) incurred to transmit the actual data bytes. It’s easy to see how loading a busy Web page over a moderately high latency path can take multiple seconds.

Recent improvements in Web page design and optimization techniques include using more CSS instead of graphics for page formatting, choosing optimal graphic formats & sizes, and consolidating & compressing CSS & JavaScript files (using Gzip) so that fewer & smaller requests are needed to build a page. In addition, current Web browsers can now employ as much as 6-8 simultaneous connections to a Web server, enabling the completion of multiple requests in a relatively short time frame. However, not all websites utilize these optimizations. Many companies are still locked into older browsers or 'chatty' legacy applications that can't or won't upgrade for some time. In this case, App Turns delays continue to be a significant factor in application performance.

As can be seen from previous discussions, network delay in all its manifestations is a significant and important factor in overall application performance—and one that certainly warrants monitoring for mission-critical applications.

Tomorrow we tackle Network Delay Measurements!

If you’re enjoying this course or have questions, please share your feedback with the community here:

 >> https://thwack.solarwinds.com/groups/dpi-online-course-study-group?CMP=EMC-MKT-SWI-DPI_Course_Lesson_3-X-TH_DPI_Login-TXT  

See you tomorrow!

Leon Adato,
Head Geek at SolarWinds
SolarWinds - The Power to Manage IT
</code> </pre>

<h1> Lesson 4: monitor delays in your network activity </h1>
<pre> <code>
Welcome to lesson 4. Today we’ll talk about how you can monitor delays in your network activity.

Network delay across a path between a client and server is often measured (by a manual process) using ICMP ‘Pings.’ It can also be observed and measured at the packet level from the amount of time that transpires between specific packets used in a sequence required for establishing client sessions with an application server. Some background information is helpful in understanding how this is accomplished.

The TCP/IP 3-Way Handshake
When a client initiates a session with an application server utilizing TCP/IP, a 3-way ‘handshake’ (TCP Handshake) takes place to set up a connection in both directions and exchanges parameters and options that establish how data is to be transferred and how error conditions should be handled.

In the first step of this 3-way handshake, the Client device sends the Server device a ‘SYN’ (Synchronize) packet that contains an Initial Sequence Number (ISN) that has been randomly generated (to defend against hacker attacks).

The server responds with a ‘SYN, ACK’ packet that contains its own Synchronization number and acknowledges the Client’s SYN request. In the last step of the handshake, the Client sends an ACK packet acknowledging the server’s SYN connection request. The Client can then send application requests to the server.

During this handshake, the Client can indicate its ability to support two enhancements to TCP in its initial SYN packet—Selective Acknowledgement (SACK) and Window Scaling. If the Server also supports these, it’s indicated in its SYN, ACK return packet. If these options are not supported by both ends of the session, they cannot be utilized. 

Selective Acknowledgement allows a device to specifically indicate a byte range it's missing due to packet loss—and by association, which bytes it might have received since the missing packet. This allows the sender to retransmit the missing data packets instead of holding up the process until it receives the lost packet(s), thereby requiring all subsequent packets to be re-sent as well.

Window Scaling is a method of indicating that a device’s receive buffer can be larger than the maximum of 65,535 bytes possible to report using the two-byte window size field in TCP headers. This maximum is indicated by a multiplier value that should be applied to the reported window size field values.

SACK and Window Scaling features can significantly improve data transport efficiency, are supported by the most recent operating systems, and can be verified by inspecting the handshake packets for each session.

Measuring Network Delay from a TCP 3-Way Handshake
From the Client end of the network path, measuring the time that transpires between the initial Client SYN packet and the Server’s SYN, ACK response packet is a reasonably accurate reflection of the Round Trip Time between Client and Server.

If the observation/capture point is at the Server end of the network path, the time between the Server’s SYN, ACK packet, and the Client’s ACK packet will reflect the network RTT time.

Finally, if the observation point is somewhere in the middle of this path, the network RTT will be reflected as the time between the Client’s initial SYN packet and the Client’s final ACK packet (3rd packet of the 3-way handshake).

About SEQ and ACK Numbers and Retransmissions
TCP Sequence (SEQ) and Acknowledgement (ACK) numbers are used by networked devices to track how much data has been transmitted and received. In addition, they track if any data packets have been lost and which ones need to be re-transmitted. They also determine the correct order to reassemble packets in case they arrive out of order.

Each time a sending device transmits a packet of data it sets the Sequence number to a value indicating the total number of bytes already sent before this packet. The receiving device then indicates that it has received this latest packet by sending an ACK packet back to the sender containing an Acknowledgement number reflecting the number of bytes it has received so far. This in turn indicates the Sequence number it expects to see in the next packet from the sender. The receiver can indicate if any packet in a series of packets gets lost and identify the missing packet by sending an ACK packet back to the sender with the Acknowledgement number of the last good packet received. As you'll remember, this indicates the Sequence number of the next expected packet. The sender will then re-transmit the missed packet.

It isn’t unusual for a relatively small number of packets to be lost during a Client/Server session. The time required for re-transmission of the lost packets isn’t significant or noticeable to the end-user. However, higher levels of packet loss from network congestion or faulty network devices can have a detrimental and noticeable effect on performance—especially when TCP back-off algorithms kick in and reduce throughput (to accommodate network congestion) on top of packet recovery processes.

You can read RFCs (Request For Comments) 793, 1122, 1323, 2018, and 5681 to get the whole picture on how TCP handles lost packets and retransmissions, congestion, and flow control. You will also get a description of how TCP optimizes performance over higher latency links.

RFCs >> http://www.ietf.org/rfc.html?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC-TXT
793 >> http://tools.ietf.org/html/rfc793?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC793-TXT
1122 >> http://tools.ietf.org/html/rfc1122?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC1122-TXT
1323 >> http://tools.ietf.org/html/rfc1323?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC1323-TXT
2018 >> http://tools.ietf.org/html/rfc2018?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC2018-TXT
5681 >> http://tools.ietf.org/html/rfc5681?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-IETF_RFC5681-TXT

Tomorrow we dive into Server Processing Time.

If you’re enjoying this course or have questions, please share your feedback with the community here:  >> https://thwack.solarwinds.com/groups/dpi-online-course-study-group?CMP=EMC-MKT-SWI-DPI_Course_Lesson_4-X-TH_DPI_Login-TXT

See you tomorrow!

Leon Adato,
Head Geek at SolarWinds
SolarWinds - The Power to Manage IT
